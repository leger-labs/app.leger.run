{
  "id": "llama-3.3-70b",
  "name": "Llama 3.3 70B",
  "maker": "meta",
  "providers": [
    {
      "id": "aws-bedrock",
      "litellm_model_name": "bedrock/meta.llama-3.3-70b",
      "is_default": true
    },
    {
      "id": "cerebras",
      "litellm_model_name": "cerebras/meta/llama-3.3-70b",
      "is_default": false
    },
    {
      "id": "groq",
      "litellm_model_name": "groq/meta/llama-3.3-70b",
      "is_default": false
    }
  ],
  "icon": "@/assets/icons/meta.svg",
  "description": "Meta AI's Llama 3.3 70B model with a 128K tokens context window available via AWS Bedrock, Cerebras, Groq",
  "capabilities": [
    "chat",
    "reasoning"
  ],
  "pricing": {
    "input_per_1m": "$0.72",
    "output_per_1m": "$0.72",
    "tier": "standard"
  },
  "use_cases": [
    "Complex analysis and planning tasks",
    "Decision support and strategy",
    "Conversational AI assistants",
    "Knowledge base Q&A",
    "Content generation and summarization"
  ],
  "notes": "Pricing and availability aggregated from provider catalogs.",
  "enabled": true,
  "context_window": 128000,
  "max_output": 32000
}
